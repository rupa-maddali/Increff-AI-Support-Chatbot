# Increff-AI-Support-Chatbot



An endâ€‘toâ€‘end, Retrievalâ€‘Augmentedâ€¯Generation (RAG) customerâ€‘support chatbot for an electronics eâ€‘commerce store.
It stores FAQs in `data/faq.json`, converts the questions into OpenAI embeddings, and indexes them with FAISS for millisecond similarity search.
At runtime the bot retrieves the topâ€‘k relevant FAQ snippets, stitches themâ€”along with the last few userâ€‘bot turnsâ€”into a concise prompt, and generates grounded answers with GPTâ€‘3.5â€‘Turbo.
The solution includes a Streamlit web UI, a CLI mode, automated pytest coverage for retrieval and multiâ€‘turn coherence, and clear guardrails for ambiguity, outâ€‘ofâ€‘scope queries, and hallucination control.



## ğŸ—ºï¸â€¯Endâ€‘toâ€‘End Process & Steps

| #  | Phase                               | What We Did                                                                                                                                                                                                                           | Key Files / Commands                                                               |
| -- | ----------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------- |
| 1  | **Projectâ€¯Scaffold**                | Created a clean repo layout:<br>`ai_support_chatbot/` â†’ `data/`, `utils/`, `tests/`, `streamlit_app.py`, etc.                                                                                                                         | â€”                                                                                  |
| 2  | **Dependency Pinning**              | Added `requirements.txt` with **OpenAI**, **faissâ€‘cpu**, **streamlit**, **pytest**, **pythonâ€‘dotenv**.                                                                                                                                | `pip install -r requirements.txt`                                                  |
| 3  | **FAQ Authoring**                   | Expanded **`data/faq.json`** to \~15 highâ€‘quality Qâ€‘A pairs covering returns, warranty, shipping, security, payment.                                                                                                                  | â€”                                                                                  |
| 4  | **Embedding & Vector Store**        | *Script*: **`embed_faq.py`**<br>â€¢ Reads `faq.json`<br>â€¢ Batches questions into **OpenAIÂ `textâ€‘embeddingâ€‘3-small`**<br>â€¢ Normalizes vectors â†’ **FAISS innerâ€‘product** index<br>â€¢ Persists `faq_faiss.index` + metadata pickle.         | `bash\npython embed_faq.py\n`                                                      |
| 5  | **Conversation Memory**             | Implemented **dequeâ€‘based** history buffer (`utils/memory.py`, default 6â€¯turns) to preserve context across multiâ€‘turn chats.                                                                                                          | â€”                                                                                  |
| 6  | **Retrieval + Generation Pipeline** | *Module*: **`chatbot.py`**<br>â€¢ Embeds user query with same OpenAI model.<br>â€¢ Retrieves topâ€‘3 FAQ snippets from FAISS.<br>â€¢ Builds lean prompt = `FAQÂ context + history + user msg`.<br>â€¢ Calls **GPTâ€‘3.5â€‘Turbo** `temperature=0.3`. | `python\nfrom chatbot import chat_once\nchat_once(\"How do I return a phone?\")\n` |
| 7  | **Streamlit UI**                    | *App*: **`streamlit_app.py`**<br>â€¢ Minimal chat frontâ€‘end.<br>â€¢ Stores chat log in `st.session_state`.<br>â€¢ Reset button clears history.                                                                                              | `bash\nstreamlit run streamlit_app.py\n`                                           |
| 8  | **CLI Utility**                     | Running `python chatbot.py` opens a REPL for quick local testing without UI overhead.                                                                                                                                                 | â€”                                                                                  |
| 9  | **Automated Tests**                 | *Tests*: **`tests/test_chatbot.py`**<br>â€¢ Retrieval correctness (keywords found).<br>â€¢ Multiâ€‘turn followâ€‘up resolution test.                                                                                                          | `pytest -q`                                                                        |
| 10 | **Edgeâ€‘Case Strategy**              | Documented 10 edge casesâ€”ambiguous queries, OOS topics, token overflow, etc.â€”and baked mitigations into prompt + code.                                                                                                                | See README Edgeâ€‘Caseâ€¯table                                                         |
| 11 | **Prompt Engineering**              | - Topâ€‘3 FAQ snippets only.<br>- History capped.<br>- Explicit guardrails: â€œAnswer ONLY from FAQ context.â€<br>- Low temperature for determinism.                                                                                       | â€”                                                                                  |
| 12 | **PDF & Docs (Optional)**           | Generated a solution PDF summarizing architecture & steps (see `AI_Intern_Assignment_Solution_Gopesh.pdf`).                                                                                                                           | â€”                                                                                  |

---

## ğŸ—ï¸â€¯Architecture & Flow Diagram

```mermaid
flowchart TD
    A[User<br>(Web / CLI)] -->|sends question| B(Streamlit Frontâ€‘end)
    B -->|API call| C[chat_once()]
    C --> D[embed_query â†’ OpenAI Embeddings]
    D --> E[FAISS Search<br>(topâ€‘3)]
    E --> F[Build Prompt<br>FAQ ctx + history + user msg]
    F --> G[GPTâ€‘3.5â€‘Turbo]
    G -->|response| H[ConversationMemory<br>append]
    H -->|final answer| B
```

---

## ğŸ”§â€¯Setup & Run

```bash
# 1. Clone & enter
git clone <repo-url>
cd ai_support_chatbot

# 2. Dependencies
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

# 3. Configure OpenAI key
cp .env.example .env          # edit with your key

# 4. Build vector index
python embed_faq.py

# 5. Launch Web UI
streamlit run streamlit_app.py
```

---

## ğŸ§ªâ€¯Testing

```bash
pytest -q
# All tests should pass:
# 3 passed in <1.0s
```

*Tests cover retrieval accuracy and multiâ€‘turn context retention.*
